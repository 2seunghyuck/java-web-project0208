{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31438b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, LeakyReLU, UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d56c89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성자 모델 만둘가\n",
    "generator = Sequential()\n",
    "generator.add(Dense(128 * 7 * 7, input_dim=100, activation=LeakyReLU(0.2)))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Reshape((7, 7, 128)))\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2D(64, kernel_size=5, padding='same'))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Activation(LeakyReLU(0.2)))\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2D(1, kernel_size=5, padding='same', activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3638658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판별자 모델 만들기\n",
    "discriminator = Sequential()\n",
    "discriminator.add(Conv2D(64, kernel_size=5, strides=2, input_shape=(28, 28, 1), padding=\"same\"))\n",
    "discriminator.add(Activation(LeakyReLU(0.2)))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Conv2D(128, kernel_size=5, strides=2, padding=\"same\"))\n",
    "discriminator.add(Activation(LeakyReLU(0.2)))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "discriminator.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfe900cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 28, 28, 1)         865281    \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 212865    \n",
      "=================================================================\n",
      "Total params: 1,078,146\n",
      "Trainable params: 852,609\n",
      "Non-trainable params: 225,537\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 생성자와 판별자 모델을 연결시키는 gan 모델 만들기\n",
    "ginput = Input(shape=(100,))\n",
    "\n",
    "dis_output = discriminator(generator(ginput))\n",
    "gan = Model(ginput, dis_output)\n",
    "gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "252152da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망을 실행시키는 함수 만들기\n",
    "def gan_train(epoch, batch_size, saving_interval):\n",
    "    # MNIST 데이터 불러오기\n",
    "    # 앞서 불러온 MNIST를 다시 이용, 테스트 과정은 필요없고 이미지만 사용할 것이기 때문에 X_train만 호출\n",
    "    (X_train, _), (_, _) = mnist.load_data()\n",
    "    X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "        # 127.5를 빼준 뒤 127.5로 나눠서 -1~1사이의 값으로 바꿈\n",
    "    X_train = (X_train - 127.5) / 127.5\n",
    "    true = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "    \n",
    "    for i in range(epoch):\n",
    "    # 실제 데이터를 판별자에 입력\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, true)\n",
    "\n",
    "        # 가상 이미지를 판별자에 입력\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "    \n",
    "        # 판별자와 생성자의 오차 계산\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        g_loss = gan.train_on_batch(noise, true)\n",
    "        print('epoch:%d' % i, ' d_loss:%.4f' % d_loss, ' g_loss:%.4f' % g_loss)\n",
    "\n",
    "    # 중간 과정을 이미지로 저장하는 부분. 정해진 인터벌만큼 학습되면 그때 만든 이미지를 gan_images 폴더에 저장하라는 뜻.\n",
    "\n",
    "    if i % saving_interval == 0:\n",
    "    # r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (25, 100))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(5, 5)\n",
    "        count = 0\n",
    "        for j in range(5):\n",
    "            for k in range(5):\n",
    "                axs[j, k].imshow(gen_imgs[count, :, :, 0], cmap='gray')\n",
    "                axs[j, k].axis('off')\n",
    "            count += 1\n",
    "        fig.savefig(\"gan_images/gan_mnist_%d.png\" % i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7168f705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0  d_loss:0.7453  g_loss:0.3945\n",
      "epoch:1  d_loss:0.5581  g_loss:0.2159\n",
      "epoch:2  d_loss:0.5222  g_loss:0.1754\n",
      "epoch:3  d_loss:0.4983  g_loss:0.2059\n",
      "epoch:4  d_loss:0.4797  g_loss:0.3237\n",
      "epoch:5  d_loss:0.4451  g_loss:0.4971\n",
      "epoch:6  d_loss:0.4130  g_loss:0.7420\n",
      "epoch:7  d_loss:0.4188  g_loss:0.8814\n",
      "epoch:8  d_loss:0.4390  g_loss:0.9091\n",
      "epoch:9  d_loss:0.7135  g_loss:0.6685\n",
      "epoch:10  d_loss:0.8435  g_loss:0.5361\n",
      "epoch:11  d_loss:0.7759  g_loss:0.5110\n",
      "epoch:12  d_loss:0.7667  g_loss:0.5198\n",
      "epoch:13  d_loss:0.7135  g_loss:0.5632\n",
      "epoch:14  d_loss:0.6095  g_loss:0.5720\n",
      "epoch:15  d_loss:0.5426  g_loss:0.6318\n",
      "epoch:16  d_loss:0.4991  g_loss:0.6649\n",
      "epoch:17  d_loss:0.5166  g_loss:0.6274\n",
      "epoch:18  d_loss:0.4550  g_loss:0.6843\n",
      "epoch:19  d_loss:0.4636  g_loss:0.7220\n",
      "epoch:20  d_loss:0.4685  g_loss:0.8652\n",
      "epoch:21  d_loss:0.4825  g_loss:0.8274\n",
      "epoch:22  d_loss:0.5162  g_loss:0.8580\n",
      "epoch:23  d_loss:0.4765  g_loss:0.8178\n",
      "epoch:24  d_loss:0.4373  g_loss:1.0164\n",
      "epoch:25  d_loss:0.3629  g_loss:1.3050\n",
      "epoch:26  d_loss:0.3107  g_loss:1.3770\n",
      "epoch:27  d_loss:0.2325  g_loss:1.5641\n",
      "epoch:28  d_loss:0.2310  g_loss:1.6694\n",
      "epoch:29  d_loss:0.1383  g_loss:1.7450\n",
      "epoch:30  d_loss:0.1201  g_loss:1.8590\n",
      "epoch:31  d_loss:0.2056  g_loss:2.2683\n",
      "epoch:32  d_loss:0.0986  g_loss:2.3560\n",
      "epoch:33  d_loss:0.1798  g_loss:1.3519\n",
      "epoch:34  d_loss:0.2902  g_loss:0.7468\n",
      "epoch:35  d_loss:0.4769  g_loss:0.4850\n",
      "epoch:36  d_loss:0.8278  g_loss:0.5682\n",
      "epoch:37  d_loss:0.9244  g_loss:1.0571\n",
      "epoch:38  d_loss:1.2332  g_loss:1.1366\n",
      "epoch:39  d_loss:0.6561  g_loss:1.2826\n",
      "epoch:40  d_loss:0.4033  g_loss:1.4203\n",
      "epoch:41  d_loss:0.1687  g_loss:1.7587\n",
      "epoch:42  d_loss:0.0813  g_loss:2.2898\n",
      "epoch:43  d_loss:0.0504  g_loss:2.7402\n",
      "epoch:44  d_loss:0.0294  g_loss:2.9686\n",
      "epoch:45  d_loss:0.0453  g_loss:3.0179\n",
      "epoch:46  d_loss:0.0301  g_loss:2.7373\n",
      "epoch:47  d_loss:0.0574  g_loss:2.9614\n",
      "epoch:48  d_loss:0.0375  g_loss:2.4615\n",
      "epoch:49  d_loss:0.0771  g_loss:4.0061\n",
      "epoch:50  d_loss:0.0613  g_loss:3.3073\n",
      "epoch:51  d_loss:0.1781  g_loss:3.4205\n",
      "epoch:52  d_loss:0.4731  g_loss:4.5167\n",
      "epoch:53  d_loss:0.2571  g_loss:6.7229\n",
      "epoch:54  d_loss:0.2606  g_loss:5.2437\n",
      "epoch:55  d_loss:0.4235  g_loss:4.0865\n",
      "epoch:56  d_loss:0.3316  g_loss:2.5858\n",
      "epoch:57  d_loss:0.3052  g_loss:2.0573\n",
      "epoch:58  d_loss:0.6366  g_loss:2.5122\n",
      "epoch:59  d_loss:0.4167  g_loss:3.3613\n",
      "epoch:60  d_loss:0.2561  g_loss:3.2809\n",
      "epoch:61  d_loss:0.4822  g_loss:3.2909\n",
      "epoch:62  d_loss:0.2193  g_loss:3.0858\n",
      "epoch:63  d_loss:0.3251  g_loss:2.5152\n",
      "epoch:64  d_loss:0.3338  g_loss:2.2362\n",
      "epoch:65  d_loss:0.3177  g_loss:2.3332\n",
      "epoch:66  d_loss:0.3109  g_loss:2.3264\n",
      "epoch:67  d_loss:0.3237  g_loss:2.6875\n",
      "epoch:68  d_loss:0.3677  g_loss:2.3432\n",
      "epoch:69  d_loss:0.3231  g_loss:2.6042\n",
      "epoch:70  d_loss:0.3761  g_loss:2.3937\n",
      "epoch:71  d_loss:0.2555  g_loss:2.7417\n",
      "epoch:72  d_loss:0.3157  g_loss:3.1471\n",
      "epoch:73  d_loss:0.2570  g_loss:3.6465\n",
      "epoch:74  d_loss:0.2235  g_loss:4.2638\n",
      "epoch:75  d_loss:0.2465  g_loss:4.1601\n",
      "epoch:76  d_loss:0.4198  g_loss:2.4641\n",
      "epoch:77  d_loss:0.4997  g_loss:2.5582\n",
      "epoch:78  d_loss:0.4027  g_loss:3.3415\n",
      "epoch:79  d_loss:0.3485  g_loss:4.4988\n",
      "epoch:80  d_loss:0.4248  g_loss:3.3888\n",
      "epoch:81  d_loss:0.5731  g_loss:2.7884\n",
      "epoch:82  d_loss:0.3763  g_loss:2.6509\n",
      "epoch:83  d_loss:0.4263  g_loss:2.2648\n",
      "epoch:84  d_loss:0.3391  g_loss:2.5379\n",
      "epoch:85  d_loss:0.3449  g_loss:2.7887\n",
      "epoch:86  d_loss:0.4235  g_loss:2.9336\n",
      "epoch:87  d_loss:0.5219  g_loss:2.5915\n",
      "epoch:88  d_loss:0.4095  g_loss:2.2348\n",
      "epoch:89  d_loss:0.5592  g_loss:1.3020\n",
      "epoch:90  d_loss:0.5464  g_loss:1.8460\n",
      "epoch:91  d_loss:0.5383  g_loss:2.2729\n",
      "epoch:92  d_loss:0.5330  g_loss:2.2850\n",
      "epoch:93  d_loss:0.3363  g_loss:2.4174\n",
      "epoch:94  d_loss:0.6299  g_loss:2.1428\n",
      "epoch:95  d_loss:0.4127  g_loss:2.4253\n",
      "epoch:96  d_loss:0.4916  g_loss:1.9919\n",
      "epoch:97  d_loss:0.4197  g_loss:2.5961\n",
      "epoch:98  d_loss:0.2486  g_loss:2.6124\n",
      "epoch:99  d_loss:0.4054  g_loss:2.3927\n",
      "epoch:100  d_loss:0.3577  g_loss:2.3044\n",
      "epoch:101  d_loss:0.4479  g_loss:2.7050\n",
      "epoch:102  d_loss:0.3523  g_loss:3.2802\n",
      "epoch:103  d_loss:0.6905  g_loss:1.9498\n",
      "epoch:104  d_loss:0.4792  g_loss:2.0532\n",
      "epoch:105  d_loss:0.5062  g_loss:2.2669\n",
      "epoch:106  d_loss:0.3825  g_loss:2.7259\n",
      "epoch:107  d_loss:0.5845  g_loss:2.3131\n",
      "epoch:108  d_loss:0.7385  g_loss:2.0987\n",
      "epoch:109  d_loss:0.6093  g_loss:1.8839\n",
      "epoch:110  d_loss:0.6275  g_loss:1.9707\n",
      "epoch:111  d_loss:0.4405  g_loss:2.1999\n",
      "epoch:112  d_loss:0.5529  g_loss:2.5866\n",
      "epoch:113  d_loss:0.4487  g_loss:2.4510\n",
      "epoch:114  d_loss:0.3208  g_loss:2.4459\n",
      "epoch:115  d_loss:0.4427  g_loss:2.4505\n",
      "epoch:116  d_loss:0.4983  g_loss:1.8546\n",
      "epoch:117  d_loss:0.5643  g_loss:1.6281\n",
      "epoch:118  d_loss:0.6604  g_loss:1.8061\n",
      "epoch:119  d_loss:0.6346  g_loss:1.7149\n",
      "epoch:120  d_loss:0.4230  g_loss:1.9530\n",
      "epoch:121  d_loss:0.5091  g_loss:1.6727\n",
      "epoch:122  d_loss:0.5391  g_loss:1.9561\n",
      "epoch:123  d_loss:0.5712  g_loss:1.9055\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1ae2b8695058>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgan_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-b6eb1ae9d1a8>\u001b[0m in \u001b[0;36mgan_train\u001b[0;34m(epoch, batch_size, saving_interval)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mgen_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0md_loss_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# 판별자와 생성자의 오차 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dl_env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dl_env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dl_env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dl_env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    266\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backwards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m           \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m           if isinstance(model.optimizer,\n\u001b[1;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dl_env/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dl_env/lib/python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/dl_env/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dl_env/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    594\u001b[0m           \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m           \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m           data_format=data_format),\n\u001b[0m\u001b[1;32m    597\u001b[0m       gen_nn_ops.conv2d_backprop_filter(\n\u001b[1;32m    598\u001b[0m           \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dl_env/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_input\u001b[0;34m(input_sizes, filter, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m         \u001b[0;34m\"explicit_paddings\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m         \"dilations\", dilations)\n\u001b[0m\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gan_train(4001, 32, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a71c66d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
